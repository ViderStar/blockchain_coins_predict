# Blockchain: predict profitable wallets

Этот ноутбук реализует следующие задачи:

- Загрузка и очистка данных оборотов токенов в течение 4 недель с 15 ноября по 13 декабря из файла tokens.csv
- Анализ данных и поиск корреляций между признаками
- Генерация комбинаций признаков с помощью различных математических преобразований
- Строит регрессионные и классификационные модели на основе линейной регрессии, полиномиальной регрессии, XGBoost,
  CatBoost, LightGBM, RandomForest
- Оценивает качество моделей на основании различных метрик
- Визуализирует результаты

Цель данного ноутбука - выбрать наилучшую комбинацию признаков и модель для предсказания доходности токенов через 6
часов после 5 минут оборота (столбец 6h_5m) на тестовой части данных. Также решить задачу отбора 10 наиболее доходных
токенов.

## Описание колонок датасета:

- **token**: обезличенный идентификатор адреса монеты
- **start_time**: дата/время старта торгов для разделения на сеты
- **5m**: предполагаемая доходность (в “иксах”) монеты если бы мы купили после старта и продали бы сейчас в 5минут.
  Учитывает комиссии монеты на покупку и продажу, не равнозначна росту цены со старта. Значение 1 значит мы получили 0
  профита.
- **start_liq**: стартовая ликвидность монеты. Ликвидность - это грубо говоря сколько реальных денег (в эфирах) сейчас
  вложено в монету. Она растет вместе с ростом цены, но нелинейно.
- **max_eth_1st**: максимальный фактический объем покупки в эфирах на старте в 1ом блоке. Он может быть очень низким
  если ограничен создателем чтобы те кто заходит ботами на старте не купили много.
- **buyers_1st**: кол-во покупателей на старте в 1ом блоке. (Сделки происходят пачкой по блокам блокчейна, один блок
  выходит раз в 12 сек)
- **buyers_1st_banana**: то же, но сколько покупателей купило с помощью популярного бота для захода в монеты
- **volume_1st**: объем торгов так же в 1ом блоке в эфирах
- **liq_x_1st**: во сколько раз выросла ликвидность в 1ом блоке (примерно то же что рост цены, решил сюда в фичи только
  “икс” ликвидности без цены выдать)
- **..1m, ..5m**: те же самые 5 фич для 1 и 5 минут со старта
- **liq_max_x_5m**: максимальный “икс” ликвидности за прошедшие 5 минут. (могло тут скакнуть в 10 раз например за
  прошедшие 5мин, а уже по факту к 5мин liq_x_5m упало до 2)
- **liq_upside_x_5m = liq_max_x_5m / liq_x_5m** - насколько сейчас ликвидность упала с максимальной
- **sell_rate_5m**: кол-во продавших за 5мин / кол-во купивших за 5 мин. редко может быть более 1 если кто-то получил
  монету не покупая, обычно не более 1.
- --и наконец выходное значение—
- **6h_5m**: предполагаемая доходность (в “иксах”) монеты если мы купим сейчас и продадим через 6 часов. Значение 1
  значит мы получили 0 профита. Значение 0 значит монета соскамилась и мы получим -100% профита.

## Этапы:

### 1. Загрузка и очистка данных

- Загружаем данные из CSV в DataFrame
- Проверяем количество пропусков в столбцах с помощью .isnull().sum()
- Заполняем пропуски медианой для числовых признаков
- Удаляем строки с пропусками методом .dropna()

### 2. Разбиение на выборки

- Берем дату старта торгов для разделения - 'start_time'
- Определяем границу тестовой выборки - последняя неделя
- Разделяем DataFrame на тренировочную и тестовую части

### 3. Анализ признаков

- Строим корреляционную матрицу методом .corr()
- Фильтруем нижнюю треугольную часть, отображаем
- Анализируем связи признаков

### 4. Генерация комбинаций

- Добавляем преобразованные столбцы (корень, логаритм и т.д.)
- Строим все возможные комбинации из столбцов
- Проверяем корреляцию комбинаций и оставляем уникальные

### 5. Обучение регрессионных моделей

- Разделяем данные на X и y
- Обучаем модели для каждой комбинации признаков: **Линейная регрессия, Полиномиальная регрессия степени 2, XGBoost,
  CatBoost, LightGBM, Random Forest**
- Предсказываем на тесте

### 6. Оценка регрессионных моделей

- Берем 10 наибольших значений предсказаний
- Считаем метрики ошибки (MSE, R2, средняя/макс ошибка)

### 7. Обучение классификационных моделей

- Размечаем целевую переменную в бинарный класс {0,1}

- Обучаем классификаторы аналогично регрессии:

  **Логистическая регрессия, Random Forest, XGBoost, CatBoost, LightGBM**

### 8. Оценка классификационных моделей

- Считаем метрики качества классификации:

    - TN, FN, TP, FP, precision, accuracy
    - Матрица ошибок

### 9. Объединение результатов

- Создаем DataFrame со всеми результатами обучения:

  all_results = pd.concat([результаты регрессии, классификации])

### 10. Визуализация точности

- Из all_results получаем DataFrame с метриками точности:

  precision_df = all_results[['Model', 'Parameters', 'Precision']]

- Строим столбчатую диаграмму точности моделей:

  fig = px.bar(precision_df, x='Model', y='Precision')

- На оси x - названия моделей, y - точность
- Подсказка на наведение мыши показывает параметры

## Следующие шаги по улучшению предсказаний модели

### Предобработка данных

- Исключение выбросов и аномалий
- Нормализация/стандартизация признаков
- Кодирование категориальных признаков

### Отбор признаков

- Анализ важности признаков в моделях
- Удаление слабозначимых признаков
- Применение методов отбора (Boruta, RFE)

### Расширение набора признаков

- Добавление статистических признаков (средних, дисперсии)
- Использование экспонент, тригонометрических функций

### Оптимизация параметров

- Сетка для гиперпараметров моделей (число деревьев, скорость обучения)

### Агрегирование моделей

- Стекинг моделей разного типа
- Взвешенная комбинация предсказаний

## Вывод модели в продакшн

### Выбор наилучшей модели

- Выбираем модель с наибольшей точностью предсказаний

### Отбор инвестиционного портфеля

- Берем выходы наилучшей модели по тестовой выборке
- Рассчитываем реальный доход инвестиционного портфеля, учитывая полученные результаты по разным метрикам

### Отчет о результатах

- Подводим итоги: лучшая модель, доходность отобранных токенов, выводы.

### Продуктивизация

- Интерактивный веб-интерфейс для загрузки/анализа новых данных
- Микросервисная архитектура для обучения и предсказаний
- Автоматическая реинжекция новых данных в модели
- Реализация повторения покупки нужных токенов, используя результаты модели и Binance API

Таким образом производится визуализация, интерпретация полученных моделей и отбор наилучшего решения задачи, а также
даны шаги для продуктивизации полученной модели.

